This commit:
------------
- "Self-taught learning" - using features learned via the sparse autoencoder

Backlog (major items):
----------------------
- have a default weight initialization
- autodiff + theano
- look into packing/deprecation
- start profiling code
- clean up the directory structure
- unit tests for demos and other functions, including gradient descent

Notes/Thoughts/Concerns:
------------------------
- All the optimization techniques assume X to be pre-appended with a row of ones at the top - should I just switch permanently to W,b, or keep this 'extended' data matrix style? 
- Currently have the data matrix as d x m, whereas most conventions use m x d - I should probably switch this at some point, but I think this will be a significant effort
